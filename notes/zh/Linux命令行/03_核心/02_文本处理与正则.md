# 🧩 文本处理与正则 (The Power of Text)

这是 Linux 区别于 Windows 的最大威力所在：**通过命令行批量处理文本内容**。

## 1. 正则表达式入门 (Regular Expressions)
正则就是“通配符”的升级版，用于精准匹配字符串。你不需要背下所有规则，掌握这 5 个符号就能解决 90% 的问题。

| 符号 | 含义 | 举例 | 匹配结果 |
| :--- | :--- | :--- | :--- |
| **`^`** | **行首** | `^Error` | 匹配以 "Error" **开头**的行 |
| **`$`** | **行尾** | `OK$` | 匹配以 "OK" **结尾**的行 |
| **`.`** | **任意字符** | `a.c` | 匹配 "abc", "a@c", "a1c" |
| **`*`** | **重复** (0次或多次) | `ab*c` | 匹配 "ac", "abc", "abbbc" |
| **`[]`** | **范围** | `[0-9]` | 匹配任意一个数字 |

> **实战组合**：
> - `^$`：匹配空行。
> - `^#`：匹配注释行 (以 # 开头)。

---

## 2. grep - 文本搜索 (配合正则)
`grep` 是正则的最佳演练场。

- **基础用法**：
  - `grep "login" app.log`：找出包含 login 的行。
  - **`grep -i "error" app.log`**：忽略大小写。
  - **`grep -E "^[0-9]{3}" app.log`**：开启扩展正则 (等同于 `egrep`)。
  - **💡 效率组合：上下文搜索**
    - `grep -C 5 "Error" app.log`：显示包含 Error 的行，及其**上下各 5 行** (Context)。
    - `grep -B 3 "Error" app.log`：显示**前** 3 行 (Before)。
    - `grep -A 3 "Error" app.log`：显示**后** 3 行 (After)。
  - `grep -v "debug" app.log`：**反向**查找。

---

## 3. cut - 快速提取列 (轻量版 awk)
当你只需要按固定分隔符提取列时，`cut` 比 `awk` 快得多。
- `cut -d ':' -f 1 /etc/passwd`
  - `-d ':'`：指定冒号为分隔符。
  - `-f 1`：提取第 1 列。

---

## 4. sed - 文本替换与修改 (Stream Editor)
不要被 `sed` 吓到，你只需要记住**一个万能公式**。

### 💡 万能替换公式
```bash
sed -i 's/旧内容/新内容/g' 文件名
```
*   **`-i`** (in-place)：**直接修改文件**。如果不加这个，sed 只是把修改后的结果打印到屏幕，不会改动原文件（这是新手的安全网）。
*   **`s`** (substitute)：表示“替换”操作。
*   **`g`** (global)：**全局替换**。如果不加 `g`，它只会替换每一行中找到的*第一个*旧内容。

### 常见场景
1.  **修改配置文件**：
    ```bash
    # 把 config.conf 里的 "debug = true" 改成 "debug = false"
    sed -i 's/debug = true/debug = false/g' config.conf
    ```

2.  **处理路径 (分隔符冲突)**：
    如果内容里有 `/` (比如路径)，再用 `/` 做分隔符会报错。这时可以用 `#` 或 `@` 代替分隔符：
    ```bash
    # 把 /var/www 改为 /home/www
    sed -i 's#/var/www#/home/www#g' config.conf
    ```

3.  **删除特定行 (`d` 模式)**：
    ```bash
    # 删除第 5 行
    sed -i '5d' file.txt
    
    # 删除所有包含 "password" 的行
    sed -i '/password/d' file.txt
    
    # 删除所有空行 (配合正则)
    sed -i '/^$/d' file.txt
    ```

---

## 4. awk - 数据提取 (列处理)
`sed` 擅长修改行，`awk` 擅长提取列。

- **核心逻辑**：默认按空格/Tab切分列。`$1` 是第一列，`$2` 是第二列，`$0` 是整行。
- **场景**：
  ```bash
  # 假设 access.log 格式为：[IP] [时间] [URL]
  # 192.168.1.1 10:00 /index.html
  
  # 只想看 IP (第1列)
  awk '{print $1}' access.log
  
  # 想看 IP 和 URL (第1列和第3列)
  awk '{print $1, $3}' access.log
  ```

---

# 5. jq - JSON 数据处理 (现代开发必备)
假设 `data.json` 内容为 `{"name": "Gemini", "version": 2.0}`。

- **`cat data.json | jq .`**：漂亮地格式化输出（带颜色和缩进）。
- **`cat data.json | jq '.name'`**：提取特定字段。
- **场景**：配合 `curl` 调用 API 后直接查看结果。

---

## 6. 终极实战：流水线组合拳
Linux 的威力在于通过管道符 `|` 将多个简单工具组合。

### 场景：统计日志中访问量最大的前 10 个 IP
假设你有一个几百 MB 的 `access.log`，你想知道谁在疯狂请求你的服务器。
```bash
cat access.log | awk '{print $1}' | sort | uniq -c | sort -rn | head -n 10
```
**步骤拆解：**
1.  **`awk '{print $1}'`**：只提取第一列（IP 地址）。
2.  **`sort`**：把相同的 IP 排在一起。
3.  **`uniq -c`**：去重并统计每个 IP 出现的次数（输出格式如：`15 192.168.1.1`）。
4.  **`sort -rn`**：按数字 (`n`) 逆序 (`r`) 再次排序，把次数最多的放最前面。
5.  **`head -n 10`**：只取前 10 行。

### 总结
- **`sed`**：适合**批量修改**、删除文件内容。
- **`awk`**：适合**分析格式化日志**、提取特定列。
- **`xargs`**：适合**把前面的结果变成参数**发给后面的命令（如 `find ... | xargs rm -f`）。
